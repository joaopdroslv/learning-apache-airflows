# Apache Airflow, DAGs (Directed Acyclic Graphs)

S√£o a estrutura fundamental para orquestrar tarefas de forma organizada e controlada. Elas representam um **fluxo de trabalho (workflow)** como um grafo direcionado e ac√≠clico, onde **cada n√≥ √© uma task (tarefa)** e as **arestas representam depend√™ncias entre elas**.

## üöÄ Conceitos Principais

1. **DAG (Direct Acyclic Graph)**
    - Define a sequ√™ncia e a depend√™ncia entre tarefas.
    - N√£o pode contner ciclos (loops), pois isso causaria exce√ß√µes infinitas.
    - Especificada via c√≥digo Python.

2. **Tasks (Tarefas)**
    - S√£o as unidades de trabalho dentro da DAG
    - Cada tarefa executa uma a√ß√£o espec√≠fica, como rodar script Python,
    chama uma API, ou interagir com um banco de dados.
    - Podem ser de diferentes tipo (Operators).

3. **Operators (Operadores)**
    - S√£o modelos pr√©-definidos de tarefas no **Airflow**.
    - Exemplos:
        - `PythonOperator` ‚Üí Executa uma fun√ß√£o Python.
        - `BashOperator` ‚Üí Executa comandos no shell.
        - `PostgresOperator` ‚Üí Executa queries em um banco de dados PostgreSQL

4. **Scheduler (Agendador)**
    - Respons√°vel por disparar a execu√ß√£o das DAGs conforme o cronograma definido.
    - Trabalha em conjunto com o *Executor* para distribuir a carga de trabalho.

5. **Executor**
    - Gerencia a execu√ß√£o das tarefas.
    - Tipos comuns:
        - `SequentialExecutor` ‚Üí Execu√ß√£o serial, uma task por vez.
        - `LocalExecutor` ‚Üí Execu√ß√£o paralela em uma √∫nica m√°quina.
        - `CeleryExecutor` ‚Üí Distribui tarefas em v√°rios workers.
        - `KubernetesExecutor` ‚Üí Cria pods din√¢micos para execu√ß√£o.

## üõ†Ô∏è Criando uma DAG no Airflow

Uma DAG √© um script Python que define um fluxo de trabalho. Exemplo b√°sico:

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

# Fun√ß√£o que ser√° executada na DAG
def hello_world():
    print("Hello, Apache Airflow!")

# Defini√ß√£o da DAG
with DAG(
    dag_id="hello_world_dag",
    start_date=datetime(2024, 1, 1),
    schedule_interval="@daily",  # Executa diariamente
    catchup=False,
) as dag:
    
    task1 = PythonOperator(
        task_id="print_hello",
        python_callable=hello_world,  # Fun√ß√£o a ser executada
    )

# Defini√ß√£o do fluxo
task1  # DAG com apenas uma tarefa
```

## üîó Defini√ß√£o de Depend√™ncias

As tarefas podem depender umas das outras, formando um fluxo de execu√ß√£o:

```python
task1 >> task2  # task2 depende de task1 (task1 -> task2)
task2 << task3  # task3 executa antes de task2 (task3 -> task2)
task3 >> [task4, task5]  # task4 e task5 s√≥ executam ap√≥s task3
```

## üìä Monitoramento

O Apache Airflow possui uma UI web onde podemos:
- Ver DAGs ativas e suas execu√ß√µes.
- Monitorar logs de tarefas.
- Modificar e pausar DAGs conforme necess√°rio.

Para iniciar a UI:

```sh
airflow webserver --port 8080
```

E para iniciar o scheduler:

```sh
airflow scheduler
```
